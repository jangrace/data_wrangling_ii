---
title: "Reading data from the web"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(rvest)
library(httr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Srape table from web:

1. I want table 1 from [this page] http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

drug_use_html = read_html(url)
```

2. extract table(s)

```{r}
drug_use_html %>% 
  html_nodes(css = "table") #this results in extracting all 15 tables, we only want table 1. but still not tibble
```

3. focus on the first table
  1. first()
  2. parse html to table via `html_table'
  3. use slice(-1) to remove first row
  4. use as_tibble to make a tibble
```{r}
tabl_marj =
drug_use_html %>% 
  html_nodes(css = "table") %>% 
  first() %>%  #extract first table, also available 'nth' 'last'
  html_table() %>% 
  slice(-1) %>% 
  as_tibble()
```

## Star Wars movie info: get data from html
```{r}
url = "https://www.imdb.com/list/ls070150896/"

swm_html = read_html(url)
```

1. grab elements I want:
  
```{r}
title_vec = 
  swm_html %>% 
  html_nodes(css = ".lister-item-header a") %>% 
  html_text()

gross_rev_vec =
  swm_html %>% 
  html_nodes(css = ".text-small:nth-child(7) span:nth-child(5)") %>% 
  html_text()

runtime_vec =
  swm_html %>% 
  html_nodes(css = ".runtime") %>% 
  html_text()

swm_df =
  tibble(
    title = title_vec,
    gross_rev = gross_rev_vec,
    runtime = runtime_vec
  )
```


## API (nyc water)

```{r}
nyc_water =
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv")
```

1. parse csv to convert to tibble
2. use content to parse as columns
3. use as_tibble
```{r}
nyc_water =
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv") %>% 
  content("parsed")
```

## BRFSS dataset (API)
```{r}
brfss_2010 = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv", 
      query = list("$limit" = 5000)) %>%  #this will get us 5000 rows of data rather than 1000
  content("parsed") #parse then will become a tibble; however, number of rows is different from actual data...Use "?GET" for further guidance
```

## some data aren't so nice...
let's look at Pokemon...

```{r}
pokemon =
  GET("https://pokeapi.co/api/v2/pokemon/1")
```

